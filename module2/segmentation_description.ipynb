{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmenting and describing regions\n",
    "\n",
    "This part of the course is about separating specific regions of interest in a image from the background automatically, and extracting descriptors from them for downstream analysis.\n",
    "\n",
    "Run the code making sure you understand the syntax. Complete the parts marked **TODO** either in the text or in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "First, we need to import some packages so that their functions are available to us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                       # operating system operations like file paths etc\n",
    "import numpy as np              # multidimensional arrays, linear algebra\n",
    "from skimage import morphology  # morphological operations\n",
    "from skimage import io          # to load and save data\n",
    "from skimage import color       # color conversion utilities\n",
    "from skimage.util import invert   # invert an image (if binary, black->white, white->black)\n",
    "from skimage import img_as_ubyte # Convert an image to 8-bits\n",
    "from skimage.filters import threshold_otsu # Otsu's thresholding method\n",
    "from skimage.measure import regionprops, regionprops_table # region properties\n",
    "\n",
    "import matplotlib.pyplot as plt # plotting\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from mpl_toolkits.mplot3d import Axes3D # 3D plotting\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "path_to_images= './data'    # Local: where the images are relative to this notebook\n",
    "#path_to_images= os.path.join('Module2','data')    # Nuvolos: where the images are relative to this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Segmentation\n",
    "\n",
    "### Baseline - Otsu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.filters import threshold_otsu\n",
    "\n",
    "# Load and normalize the neuroblastoma image\n",
    "image_file = os.path.join(path_to_images, 'neuroblastoma_5_orig_small.jpg')\n",
    "img = io.imread(image_file)\n",
    "img = img/np.max(img) # normalize the image to [0,1]\n",
    "print(f'Image has shape {img.shape}')\n",
    "\n",
    "# threshold the image with Otsu's method\n",
    "thresh = threshold_otsu(img)\n",
    "binary_img = img > thresh\n",
    "\n",
    "# look for connected components to count cells\n",
    "labeled_img, num_labels = morphology.label(binary_img, background=0, return_num=True, connectivity=1)\n",
    "print(f'Found {num_labels} connected components')\n",
    "\n",
    "\n",
    "# Display the original image, the Sobel the detected edges side by side\n",
    "fig, axes = plt.subplots(1, 3, figsize=(14, 7))\n",
    "axes[0].imshow(img, cmap='gray')\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "axes[1].imshow(binary_img, cmap='gray')\n",
    "axes[1].set_title('Otsu-thresholded image')\n",
    "axes[1].axis('off')\n",
    "axes[2].imshow(labeled_img, cmap='tab20c')\n",
    "axes[2].set_title('CC-labelled image')\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Watershed\n",
    "\n",
    "#### Principles - intensity is height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and normalize the neuroblastoma image\n",
    "image_file = os.path.join(path_to_images, 'neuroblastoma_5_orig_small.jpg')\n",
    "img = io.imread(image_file)\n",
    "img = img/np.max(img) # normalize the image to [0,1]\n",
    "\n",
    "plt.imshow(img, cmap='gray', origin='lower')\n",
    "plt.title('Original Image')\n",
    "plt.xlabel('X')\n",
    "plt.ylabel('Y')\n",
    "\n",
    "\n",
    "# Create a grid spanning x, y coordinates\n",
    "x = range(img.shape[1])\n",
    "y = range(img.shape[0])\n",
    "X, Y = np.meshgrid(x, y)\n",
    "\n",
    "# Create z values from the gray-level values of each pixel\n",
    "Z = img\n",
    "\n",
    "# Create a 3D plot\n",
    "fig = plt.figure(figsize=(10, 10)) \n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.view_init(elev=120, azim=90, roll=180)\n",
    "ax.plot_surface(X, Y, Z, cmap='gray')\n",
    "\n",
    "# Set labels and title\n",
    "ax.set_xlabel('X')\n",
    "ax.set_ylabel('Y')\n",
    "ax.set_zlabel('Gray-level value')\n",
    "ax.set_title('Topographic view')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Full Watershed algorithm\n",
    "\n",
    "Let's implement all the steps needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WATERSHED SEGMENTATION\n",
    "from scipy import ndimage as ndi\n",
    "from skimage.feature import peak_local_max\n",
    "from skimage.segmentation import watershed\n",
    "\n",
    "# Load and normalize the neuroblastoma image\n",
    "image_file = os.path.join(path_to_images, 'neuroblastoma_5_orig_small.jpg')\n",
    "img = io.imread(image_file)\n",
    "img = img/np.max(img) # normalize the image to [0,1]\n",
    "\n",
    "# Binarize by thresholding, then invert\n",
    "img_bin=img < 0.2\n",
    "img_bin_inv = invert(img_bin)\n",
    "\n",
    "# compute distance transform - shortest distance from this pixel to the background\n",
    "img_dist = ndi.distance_transform_edt(img_bin_inv)\n",
    "\n",
    "\n",
    "# find coordinates of local maxima in distance transform image\n",
    "coords_max = peak_local_max(img_dist, footprint=np.ones((25,25)), labels=img_bin_inv)\n",
    "print(f'Found {coords_max.shape[0]} local maxima')\n",
    "\n",
    "# create an image with these coordinates marked as True\n",
    "local_maxima = np.zeros(img_dist.shape, dtype=bool)\n",
    "local_maxima[tuple(coords_max.T)] = True\n",
    "print(f'Local maxima image has {np.sum(local_maxima.ravel())} marked points')\n",
    "\n",
    "# now create markers for the watershed algorithm, use one-connected neighbourhoods to define whether\n",
    "# two local maxima should be merged\n",
    "markers, _ = ndi.label(local_maxima)\n",
    "print(f'Markers image has {len(np.unique(markers))-1} markers') # -1 because 0 is background\n",
    "print(f'Cell labels: {np.unique(markers)}')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Run watershed algorithm to label each pixel with the marker of the local maximum it is closest to\n",
    "labels = watershed(img_dist, markers, mask=img_bin_inv, compactness=1)\n",
    "print(f'Watershed algorithm found {len(np.unique(labels))-1} unique labels') # -1 because 0 is background\n",
    "\n",
    "# Show all processing steps in Watershed segmentation\n",
    "fig, axes = plt.subplots(3, 3, figsize=(32, 30))\n",
    "axes[0,0].imshow(img, cmap='gray')\n",
    "axes[0,0].set_title('1. Image')\n",
    "axes[0,0].axis('off')\n",
    "axes[0,1].imshow(img_bin, cmap='gray')\n",
    "axes[0,1].set_title('2. Thresholded Image')\n",
    "axes[0,1].axis('off')\n",
    "axes[0,2].imshow(img_bin_inv, cmap='gray')\n",
    "axes[0,2].set_title('3. Inverted thresholded')\n",
    "axes[0,2].axis('off')\n",
    "\n",
    "axes[1,0].imshow(img_dist, cmap='gray')\n",
    "axes[1,0].set_title('3. Distance Transform')\n",
    "axes[1,0].axis('off')\n",
    "axes[1,1].imshow(local_maxima, cmap='gray')\n",
    "axes[1,1].set_title('4. Local maxima in Distance Transform')\n",
    "axes[1,1].axis('off')\n",
    "axes[1,1].scatter(coords_max[:,1], coords_max[:,0], c='y', s=20, marker=\"+\", alpha=0.5)\n",
    "axes[1,2].imshow(markers, cmap='gray')\n",
    "axes[1,2].set_title('5.  Maximum markers')\n",
    "axes[1,2].axis('off')\n",
    "\n",
    "# Find non-zero pixels in the markers image\n",
    "non_zero_pixels = markers[markers != 0]\n",
    "\n",
    "# Plot a string equal to the value of the non-zero pixel at that location in the image\n",
    "axes[2,0].imshow(markers, cmap='gray')\n",
    "for i, pixel in enumerate(non_zero_pixels):\n",
    "    row, col = np.where(markers == pixel)\n",
    "    axes[2,0].text(col[0], row[0], str(pixel), color='red', fontsize=12)\n",
    "axes[2,0].set_title('6. Max markers w/ labels')\n",
    "axes[2,0].axis('off')\n",
    "\n",
    "axes[2,1].imshow(labels, cmap='tab20c')\n",
    "axes[2,1].set_title('7. Watershed Labels')\n",
    "axes[2,1].axis('off')\n",
    "\n",
    "# count the number of pixels in each labelled cell\n",
    "unique_labels, label_counts = np.unique(labels[labels>0].ravel(), return_counts=True)\n",
    "axes[2,2].bar(unique_labels, label_counts, align='center')\n",
    "axes[2,2].set_xticks(unique_labels)\n",
    "axes[2,2].set_title('Cell sizes (in pixels)')\n",
    "axes[2,2].set_xlabel('Cell ID')\n",
    "axes[2,2].set_ylabel('Number of pixels')\n",
    "\n",
    "\n",
    "plt.tight_layout(pad=0.3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see this algorithm has many steps, in addition to the usual preprocessing steps such as normalizing, thresholding etc.\n",
    "\n",
    "Let's examine one by one the effect of the steps.\n",
    "\n",
    "**TODO** What is the effect of the size structuring element (\"footprint\" in skimage lingo) used to detect local maxima of the distance function? Try modifying it. Do you get fewer, more, or the same number of local maxima? Why does this happen? \n",
    "\n",
    "**TODO** What is the effect of the compactness parameter in the Watershed algorithm?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "\n",
    "We already have our very first region descriptor just from counting pixels - region size (area)! in many applications such as flow cytometry, cell size is an important parameter. but we can do much more.\n",
    "\n",
    "The function [`regionprops`](https://scikit-image.org/docs/stable/api/skimage.measure.html#skimage.measure.regionprops) in `skimage.measure` can extract basic geometric descriptors, moments, XXX.\n",
    "\n",
    "You can also use [`regionprops_table`](https://scikit-image.org/docs/stable/api/skimage.measure.html#skimage.measure.regionprops_table) (recommended) and get back a Python dictionary that can be easily converted into a Pandas dataframe for visualization or downstream analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic geometric descriptors\n",
    "\n",
    "To extract the descriptors you want, just pass them as a list of strings to the `properties` argument of the `regionprops_table` function. See below for an example.\n",
    "\n",
    "Here we will look at \n",
    "\n",
    "- Area: 'area'\n",
    "- Perimeter: 'perimeter'\n",
    "\n",
    "\n",
    "\n",
    "Let's start by computing the area of each region. Note that the unit of measurement is pixels because we don't know the resolution of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_properties=regionprops_table(labels,intensity_image=img, properties=['label','area'])\n",
    "df_rp=pd.DataFrame(region_properties)\n",
    "print(df_rp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO** check that you obtain the same numbers as with the previous 'manual' computation using `np.unique`.\n",
    "\n",
    "Now, let's look at other properties. Our aim for example is to see if we can distinguish cells that have similar sizes, but different shapes. For example let's try to find a way to distinguish cells 11 and 4, and cells 15 and 16."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "region_properties=regionprops_table(labels,intensity_image=img, properties=['label','area','perimeter'])\n",
    "df_rp=pd.DataFrame(region_properties)\n",
    "\n",
    "# we can use matplotlib.pyplot commands directly from pandas, which makes it easier to reference columns\n",
    "df_rp.plot.scatter(x='area',y='perimeter',c='label', cmap='tab20c')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, adding perimeter as second dimension makes the difference between cells clearer - cells with the same area (x-axis) can have very different perimeters (y-axis). These descriptors form a *feature space* that we can use to quantify cells and their differences.\n",
    "\n",
    "For example, we could measure separation between cells 11 and 4, and cells 15 and 16 objectively by measuring their Euclidean distance. Since the scales are different between area and perimeter, we would need to normalise each between 0 and 1 first (or use Standardization by removing the mean and dividing by the standard deviation), then compute the distance.\n",
    "\n",
    "**BONUS** implement this and measure distances between these cells!\n",
    "\n",
    "Now, let's see how to implement our own descriptors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute compactness ourselves \n",
    "# (we could also rely on regionprops 'equivalent_diameter_area' property)\n",
    "df_rp['compactness']=4*np.pi*df_rp['area']/df_rp['perimeter']**2\n",
    "\n",
    "df_rp.plot.scatter(x='area',y='compactness',c='label', cmap='tab20c')\n",
    "\n",
    "print(df_rp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, looking at area, perimeter, compactness - what is the best way to distinguish cells 11 vs 4? and 15 vs 16? Is there a good way in both cases?\n",
    "\n",
    "**TODO** Copy-paste descriptors for 11 vs 4 and 15 vs 16 to support your argument numerically. Check the original image to see if the descriptors correspond to your intuitive understanding of the differences between the cells."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moment descriptors\n",
    "\n",
    "As you can see, simple geometric descriptors are not necessarily sufficient to distinguish cells that look different to the human eye.\n",
    "\n",
    "We can go further by using image moments, providing global descriptors. First-order moments describe the density of the shape. Second-order moments describe rate of change in a shape's properties such as area. We can look at \n",
    "\n",
    "- Orientation: 'orientation' - orientation of the major axis of the ellipse having the same second moments as the region\n",
    "- Moments: 'moments' - these are not invariant to translation, scale, or rotation\n",
    "- Normalized moments: 'moments_normalized' - invariant to translation and scale but not rotation\n",
    "- Normalized central moments (Hu 1972): 'moments_hu' - invariant to translation, scaling, rotation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_properties_moments=regionprops_table(labels,intensity_image=img, properties=['label','orientation','moments_hu'])\n",
    "df_rp_moments=pd.DataFrame(region_properties_moments)\n",
    "\n",
    "df_rp_full=pd.merge(df_rp,df_rp_moments,on='label')\n",
    "\n",
    "df_rp_full.plot.scatter(x='area',y='moments_hu-2',c='label', cmap='tab20c',logy=True)\n",
    "\n",
    "df_rp_full\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the difference between cells should be more obvious. As you introduce more an higher-order descriptors, you have a higher chance of separating cells that may look similar with simpler descriptors. At the same time, this may highlight irrelevant differences.\n",
    "\n",
    "**TODO** Decide which combination of basic descriptors and moment descriptors gives you the best separation between cells 4 vs 11, 15 vs 16."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BONUS** To get a broader understanding of the sensitivity of methods to change in data, replicate the watershed segmentation pipeline + descriptors extraction below using the bacilli image. What are the most important changes you have to implement? "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
